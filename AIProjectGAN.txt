import numpy as np
from keras.models import Sequential, Model
from keras.layers import Dense, Reshape, Conv2DTranspose, Conv2D, Flatten, Dropout, LeakyReLU, Input
from keras.optimizers import Adam
import matplotlib.pyplot as plt
from keras.datasets import cifar10

# Load CIFAR-10 dataset and filter for cat images (class label 3)
(X_train, y_train), (_, _) = cifar10.load_data()
cat_images = X_train[y_train.flatten() == 3]  # Filter cat images (label 3)
cat_images = cat_images.astype('float32') / 255.0  # Normalize to [0, 1]
cat_images = (cat_images - 0.5) * 2.0  # Normalize to [-1, 1]

def build_generator(input_shape=(32, 32, 3)):
    img_input = Input(shape=input_shape)

    # Convolutional layers to modify the input image
    x = Conv2D(64, kernel_size=4, strides=2, padding='same')(img_input)
    x = LeakyReLU(alpha=0.2)(x)
    x = Dropout(0.4)(x)
    
    x = Conv2D(128, kernel_size=4, strides=2, padding='same')(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = Dropout(0.4)(x)

    x = Flatten()(x)
    x = Dense(128, activation='relu')(x)
    x = Dense(np.prod(input_shape), activation='tanh')(x)
    x = Reshape(input_shape)(x)

    generated_img = x  # Generate modified image from input image
    
    return Model(img_input, generated_img)


def build_discriminator(input_shape=(32, 32, 3)):
    img_input = Input(shape=input_shape)

    # Convolutional layers for image input
    x = Conv2D(64, kernel_size=4, strides=2, padding='same', activation='relu')(img_input)
    x = Dropout(0.4)(x)
    x = Conv2D(128, kernel_size=4, strides=2, padding='same', activation='relu')(x)
    x = Dropout(0.4)(x)
    x = Flatten()(x)

    # Fully connected layer for real/fake classification
    x = Dense(1, activation='sigmoid')(x)

    # Define the discriminator model
    discriminator = Model(img_input, x)

    # Compile the discriminator
    discriminator.compile(optimizer=Adam(learning_rate=0.00035, beta_1=0.5), loss='binary_crossentropy', metrics=['accuracy'])

    return discriminator


def build_gan(generator, discriminator):
    discriminator.trainable = False  # Freeze the discriminator during GAN training
    model = Sequential()
    model.add(generator)
    model.add(discriminator)
    opt = Adam(learning_rate=0.00025, beta_1=0.5)
    model.compile(optimizer=opt, loss='binary_crossentropy')
    return model


def generate_real_samples(dataset, n_samples):
    idx = np.random.randint(0, dataset.shape[0], n_samples)
    X = dataset[idx]  # Real cat images
    y = np.ones((n_samples, 1))  # Real images have label 1
    return X, y


def generate_fake_samples(generator, dataset, n_samples):
    idx = np.random.randint(0, dataset.shape[0], n_samples)
    X_real = dataset[idx]  # Get random cat images
    X_fake = generator.predict(X_real)  # Generate fake images from the real images
    y = np.zeros((n_samples, 1))  # Fake images have label 0
    return X_fake, y


def train_gan(generator, discriminator, gan, dataset, epochs=100, batch_size=64):
    bat_per_epoch = int(dataset.shape[0] / batch_size)
    half_batch = int(batch_size / 2)

    for epoch in range(epochs):
        for batch in range(bat_per_epoch):
            # Train discriminator on real cat images
            X_real, y_real = generate_real_samples(dataset, half_batch)
            d_loss_real, _ = discriminator.train_on_batch(X_real, y_real)

            # Train discriminator on fake cat images generated by the generator
            X_fake, y_fake = generate_fake_samples(generator, dataset, half_batch)
            d_loss_fake, _ = discriminator.train_on_batch(X_fake, y_fake)

            # Train generator via GAN (fake images classified as real)
            indices = np.random.choice(len(dataset), size=batch_size, replace=False)
            X_real_for_gan = dataset[indices]
           # X_real_for_gan = np.random.randint(dataset, size=batch_size)  # Use real images as input to the generator
            y_gan = np.ones((batch_size, 1))  # Labels for fake images are 1 (as generator is trying to fool discriminator)
            
            g_loss = gan.train_on_batch(X_real_for_gan, y_gan)

        # Periodically save generated images
        if (epoch + 1) % 10 == 0:
            X_fake, _ = generate_fake_samples(generator, dataset, 16)
            plt.figure(figsize=(8, 8))
            for i in range(16):
                plt.subplot(4, 4, i + 1)
                plt.axis('off')
                plt.imshow((X_fake[i] + 1) / 2)  # Rescale to [0, 1]
            plt.savefig(f'generated_epoch_{epoch + 1}.png')
            plt.close()


# Build models
generator = build_generator()
discriminator = build_discriminator()
gan = build_gan(generator, discriminator)

# Train the GAN
train_gan(generator, discriminator, gan, cat_images, epochs=100, batch_size=64)
